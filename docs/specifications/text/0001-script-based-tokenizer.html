<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Welcome to the Meilisearch dev specifications!</title>
    <meta name="generator" content="VuePress 1.9.7">
    
    <meta name="description" content="">
    
    <link rel="preload" href="/assets/css/0.styles.b26ff90a.css" as="style"><link rel="preload" href="/assets/js/app.9c8da528.js" as="script"><link rel="preload" href="/assets/js/3.7860be15.js" as="script"><link rel="preload" href="/assets/js/14.9305fa09.js" as="script"><link rel="prefetch" href="/assets/js/10.867f19e5.js"><link rel="prefetch" href="/assets/js/11.72b45679.js"><link rel="prefetch" href="/assets/js/12.2af66f08.js"><link rel="prefetch" href="/assets/js/13.167021d3.js"><link rel="prefetch" href="/assets/js/15.d80f77d0.js"><link rel="prefetch" href="/assets/js/16.055f279b.js"><link rel="prefetch" href="/assets/js/17.13c224fe.js"><link rel="prefetch" href="/assets/js/18.f87d82ff.js"><link rel="prefetch" href="/assets/js/19.1374b4fc.js"><link rel="prefetch" href="/assets/js/20.61ccbe96.js"><link rel="prefetch" href="/assets/js/21.d9d2de27.js"><link rel="prefetch" href="/assets/js/22.651633e9.js"><link rel="prefetch" href="/assets/js/23.3bd00f1a.js"><link rel="prefetch" href="/assets/js/24.54ad58be.js"><link rel="prefetch" href="/assets/js/25.d0799eb0.js"><link rel="prefetch" href="/assets/js/26.f7d33dc0.js"><link rel="prefetch" href="/assets/js/27.97cd9936.js"><link rel="prefetch" href="/assets/js/28.5e3fb46d.js"><link rel="prefetch" href="/assets/js/29.3402d6e4.js"><link rel="prefetch" href="/assets/js/30.f8896eb5.js"><link rel="prefetch" href="/assets/js/31.02252265.js"><link rel="prefetch" href="/assets/js/32.d110bd72.js"><link rel="prefetch" href="/assets/js/33.0f295cc3.js"><link rel="prefetch" href="/assets/js/34.54f24532.js"><link rel="prefetch" href="/assets/js/35.9cfaf523.js"><link rel="prefetch" href="/assets/js/36.ab86608b.js"><link rel="prefetch" href="/assets/js/37.4a942ee2.js"><link rel="prefetch" href="/assets/js/38.7cba70e5.js"><link rel="prefetch" href="/assets/js/39.309b7c24.js"><link rel="prefetch" href="/assets/js/4.7c96fa1c.js"><link rel="prefetch" href="/assets/js/40.62fdcecb.js"><link rel="prefetch" href="/assets/js/41.680f64e6.js"><link rel="prefetch" href="/assets/js/42.89dccdf9.js"><link rel="prefetch" href="/assets/js/43.89fa855e.js"><link rel="prefetch" href="/assets/js/44.82c75e0e.js"><link rel="prefetch" href="/assets/js/45.c45f1bf9.js"><link rel="prefetch" href="/assets/js/46.e4da27a1.js"><link rel="prefetch" href="/assets/js/47.73e2a9b1.js"><link rel="prefetch" href="/assets/js/48.4c5f8c16.js"><link rel="prefetch" href="/assets/js/49.66e94cb8.js"><link rel="prefetch" href="/assets/js/5.06848b4d.js"><link rel="prefetch" href="/assets/js/50.a20bd5a0.js"><link rel="prefetch" href="/assets/js/51.84e2032f.js"><link rel="prefetch" href="/assets/js/52.ee64393c.js"><link rel="prefetch" href="/assets/js/53.f4e4e57a.js"><link rel="prefetch" href="/assets/js/54.f9b5fd5d.js"><link rel="prefetch" href="/assets/js/55.e3f602d7.js"><link rel="prefetch" href="/assets/js/56.443da874.js"><link rel="prefetch" href="/assets/js/6.87f02c74.js"><link rel="prefetch" href="/assets/js/7.fadbe260.js"><link rel="prefetch" href="/assets/js/8.d45b99a8.js"><link rel="prefetch" href="/assets/js/9.0c014273.js"><link rel="prefetch" href="/assets/js/vendors~docs-searchbar.9a2822a3.js">
    <link rel="stylesheet" href="/assets/css/0.styles.b26ff90a.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><!----> <span class="site-name">Welcome to the Meilisearch dev specifications!</span></a> <div class="links"><form id="search-form" role="search" class="meilisearch-search-wrapper search-box"><input id="meilisearch-search-input" class="search-query"></form> <nav class="nav-links can-hide"><div class="nav-item"><a href="/specifications/text/specifications/text/0000-specification-template.html" class="nav-link">
  Specification
</a></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/specifications/text/specifications/text/0000-specification-template.html" class="nav-link">
  Specification
</a></div> <!----></nav>  <ul class="sidebar-links"><li><a href="/specifications/text/0000-specification-template.html" class="sidebar-link">Specification template</a></li><li><a href="/specifications/text/0001-frontend-disable-prod.html" class="sidebar-link">Frontend disable prod</a></li><li><a href="/specifications/text/0001-script-based-tokenizer.html" aria-current="page" class="active sidebar-link">Script based tokenizer</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/specifications/text/0001-script-based-tokenizer.html#feature-description-and-interaction" class="sidebar-link">Feature Description and Interaction</a></li><li class="sidebar-sub-header"><a href="/specifications/text/0001-script-based-tokenizer.html#technical-specifications" class="sidebar-link">Technical Specifications</a></li><li class="sidebar-sub-header"><a href="/specifications/text/0001-script-based-tokenizer.html#future-possibilities" class="sidebar-link">Future possibilities</a></li></ul></li><li><a href="/specifications/text/0028-indexing-csv.html" class="sidebar-link">Indexing csv</a></li><li><a href="/specifications/text/0029-indexing-ndjson.html" class="sidebar-link">Indexing ndjson</a></li><li><a href="/specifications/text/0030-asc-desc-criterion.html" class="sidebar-link">Asc desc criterion</a></li><li><a href="/specifications/text/0032-distinct-attribute.html" class="sidebar-link">Distinct attribute</a></li><li><a href="/specifications/text/0033-logging.html" class="sidebar-link">Logging</a></li><li><a href="/specifications/text/0034-telemetry-policies.html" class="sidebar-link">Telemetry policies</a></li><li><a href="/specifications/text/0036-exactness-criterion.html" class="sidebar-link">Exactness criterion</a></li><li><a href="/specifications/text/0038-rename-attributes-for-faceting.html" class="sidebar-link">Rename attributes for faceting</a></li><li><a href="/specifications/text/0043-phrase-query.html" class="sidebar-link">Phrase query</a></li><li><a href="/specifications/text/0047-reset-stop-words-synonyms-settings-with-null.html" class="sidebar-link">Reset stop words synonyms settings with null</a></li><li><a href="/specifications/text/0048-rename-max-mdb-size-var.html" class="sidebar-link">Rename max mdb size var</a></li><li><a href="/specifications/text/0055-sort.html" class="sidebar-link">Sort</a></li><li><a href="/specifications/text/0059-geo-search.html" class="sidebar-link">Geo search</a></li><li><a href="/specifications/text/0060-tasks-api.html" class="sidebar-link">Tasks api</a></li><li><a href="/specifications/text/0061-error-format-and-definitions.html" class="sidebar-link">Error format and definitions</a></li><li><a href="/specifications/text/0077-words-position-limit.html" class="sidebar-link">Words position limit</a></li><li><a href="/specifications/text/0085-api-keys.html" class="sidebar-link">Api keys</a></li><li><a href="/specifications/text/0089-tenant-tokens.html" class="sidebar-link">Tenant tokens</a></li><li><a href="/specifications/text/0096-auto-batching.html" class="sidebar-link">Auto batching</a></li><li><a href="/specifications/text/0105-dumps-api.html" class="sidebar-link">Dumps api</a></li><li><a href="/specifications/text/0117-typo-tolerance-setting-api.html" class="sidebar-link">Typo tolerance setting api</a></li><li><a href="/specifications/text/0118-search-api.html" class="sidebar-link">Search api</a></li><li><a href="/specifications/text/0119-instance-options.html" class="sidebar-link">Instance options</a></li><li><a href="/specifications/text/0121-data-types.html" class="sidebar-link">Data types</a></li><li><a href="/specifications/text/0123-displayed-attributes-setting-api.html" class="sidebar-link">Displayed attributes setting api</a></li><li><a href="/specifications/text/0123-distinct-attribute-setting-api.html" class="sidebar-link">Distinct attribute setting api</a></li><li><a href="/specifications/text/0123-filterable-attributes-setting-api.html" class="sidebar-link">Filterable attributes setting api</a></li><li><a href="/specifications/text/0123-ranking-rules-setting-api.html" class="sidebar-link">Ranking rules setting api</a></li><li><a href="/specifications/text/0123-searchable-attributes-setting-api.html" class="sidebar-link">Searchable attributes setting api</a></li><li><a href="/specifications/text/0123-settings-api.html" class="sidebar-link">Settings api</a></li><li><a href="/specifications/text/0123-sortable-attributes-setting-api.html" class="sidebar-link">Sortable attributes setting api</a></li><li><a href="/specifications/text/0123-stop-words-setting-api.html" class="sidebar-link">Stop words setting api</a></li><li><a href="/specifications/text/0123-synonyms-setting-api.html" class="sidebar-link">Synonyms setting api</a></li><li><a href="/specifications/text/0124-documents-api.html" class="sidebar-link">Documents api</a></li><li><a href="/specifications/text/0132-indexes-api.html" class="sidebar-link">Indexes api</a></li><li><a href="/specifications/text/0134-stats-api.html" class="sidebar-link">Stats api</a></li><li><a href="/specifications/text/0135-indexing-json.html" class="sidebar-link">Indexing json</a></li><li><a href="/specifications/text/0136-documents-soft-deletion.html" class="sidebar-link">Documents soft deletion</a></li><li><a href="/specifications/text/0171-version-api.html" class="sidebar-link">Version api</a></li><li><a href="/specifications/text/0172-health-api.html" class="sidebar-link">Health api</a></li><li><a href="/specifications/text/157-faceting-setting-api.html" class="sidebar-link">Aceting setting api</a></li><li><a href="/specifications/text/157-pagination-setting-api.html" class="sidebar-link">Agination setting api</a></li></ul> </aside> <main class="page"> <div class="theme-default-content content__default"><ul><li>Title: Script Based Tokenizer</li> <li>Start Date: 2020-10-27</li> <li>specification PR: meilisearch/specifications#2</li> <li>Meilisearch Issue: meilisearch/Meilsearch#624</li></ul> <h2 id="feature-description-and-interaction"><a href="#feature-description-and-interaction" class="header-anchor">#</a> Feature Description and Interaction</h2> <h3 id="summary"><a href="#summary" class="header-anchor">#</a> Summary</h3> <p>The first step of document indexing in the Meilisearch engine is tokenization. Tokenization is the action of taking a sentence and splitting it in units of language called tokens. The tokenization task is highly language dependant and is a critical factor in the quality of the search results.</p> <h3 id="motivation"><a href="#motivation" class="header-anchor">#</a> Motivation</h3> <p>We want to provide our users with an always improved searching experience. For that matter, it is critical for us to improve the performance of our tokenizer, and to provide better support for multilingual tokenization.</p> <h3 id="prior-art-and-r-d"><a href="#prior-art-and-r-d" class="header-anchor">#</a> Prior Art and R&amp;D</h3> <p><strong>tokenization:</strong></p> <ul><li><blockquote><p><strong><a href="https://github.com/unicode-rs/unicode-segmentation" target="_blank" rel="noopener noreferrer">unicode-segmentation<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>:</strong>
tokenizer which follow the <a href="http://www.unicode.org/reports/tr29/" target="_blank" rel="noopener noreferrer">Standard Annex #29: Unicode Text Segmentation<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>,
this tokenizer seems promising for Latin scripts.</p></blockquote></li> <li><blockquote><p><strong><a href="https://github.com/messense/jieba-rs" target="_blank" rel="noopener noreferrer">Jieba<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>:</strong>
tokenizer specialized in Chinese languages</p></blockquote></li> <li><blockquote><p><strong><a href="https://github.com/lindera-morphology/lindera" target="_blank" rel="noopener noreferrer">Lindera<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>:</strong>
Japanese and Korean</p></blockquote></li></ul> <p><strong>lang/script detection:</strong></p> <ul><li><blockquote><p><strong><a href="https://github.com/greyblake/whatlang-rs" target="_blank" rel="noopener noreferrer">whatlang<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>:</strong>
whatlang is able to detect script or/and language in a text,
language detection is low but the script is acceptable.
note: Sonic also uses whatlang to perform the tokenization, it could be interesting to check out how they do it.</p></blockquote></li> <li><blockquote><p><strong>toku (@qdequele):</strong>
in a R&amp;D project, @qdequele was able to detect language based on stop word distribution in a text.
If, in a latin script, there is lot of French stop words then the text language is probably french.</p></blockquote></li></ul> <p><strong>other solution that advertise multilingual support:</strong></p> <ul><li>Sonic uses whatlang to perform the tokenization, it could be interesting to checkout how they do it: https://github.com/valeriansaliou/sonic/tree/master/src/lexer
<ul><li>Sonic uses whatlang to detect the languages but doesn't actually seem to use it to segment the text. It simply uses unicode segmentation, I can't really explain what they actually do with the language information.</li></ul></li> <li>tantivy advertise good multilingual support: https://github.com/tantivy-search/tantivy/tree/main/src/tokenizer
<ul><li>Tantivy is similar to elastic in the sense that you can set up a custom text analyzer. The difference is that it is only made of <code>tokenizer</code> -&gt; <code>token_filter</code>. Tantivy also provides a collection of tokenizer to choose from. Tokens are rather simple and do not contain any metadata, except for their position.</li></ul></li> <li>How elastic search handle it: https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-tokenizers.html:
<ul><li>Elastic proposed to create custom text analyzer. A text analyzer is a pipelined text processor with the following components: <code>char_filter</code> -&gt; <code>tokenizer</code> -&gt; <code>token_filter</code>. There are multiple different tokenizers that can be chosen, depending on the use-case. This is a bit complicated, but I also think that advanced users should be able to choose the tokenizer they want. (default behavior is us guessing what's the best tokenizer to use.)</li></ul></li> <li>Algolia:
<ul><li>Algolia uses multiple techniques to handle tokenization. They start by <a href="https://www.algolia.com/doc/guides/managing-results/optimize-search-results/handling-natural-languages-nlp/in-depth/normalization/" target="_blank" rel="noopener noreferrer">normalizing<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> the text (lowercase, unidecode, transform traditional Chinese to modern, etc). Then, they tokenize the normalized data. It seems that the tokenization is based on two techniques. The first one is by <a href="https://www.algolia.com/doc/guides/managing-results/optimize-search-results/handling-natural-languages-nlp/in-depth/tokenization/" target="_blank" rel="noopener noreferrer">defining separators<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> (space, comma, carriage return, etc) and the other one is with <a href="https://www.algolia.com/doc/guides/managing-results/optimize-search-results/handling-natural-languages-nlp/#using-dictionaries" target="_blank" rel="noopener noreferrer">dictionaries<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>. The language is not automatically detected, <a href="https://www.algolia.com/doc/guides/managing-results/optimize-search-results/handling-natural-languages-nlp/#no-automatic-language-detection" target="_blank" rel="noopener noreferrer">it must be set by the user<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>. They also have dictionaries for plurals.</li></ul></li></ul> <h3 id="explanation"><a href="#explanation" class="header-anchor">#</a> Explanation</h3> <p>In order to use the tokenizer, all the user has to do is to instantiate a <code>Tokenizer</code>, call <code>tokenize(&amp;str)</code> on it and iterate over the emitted tokens:</p> <div class="language-rust extra-class"><pre class="language-rust"><code>    <span class="token keyword">use</span> <span class="token namespace">fst<span class="token punctuation">::</span></span><span class="token class-name">Set</span><span class="token punctuation">;</span>
    
    <span class="token keyword">use</span> <span class="token namespace">charabia<span class="token punctuation">::</span></span><span class="token class-name">TokenizerBuilder</span><span class="token punctuation">;</span>
    
    <span class="token comment">// text to tokenize.</span>
    <span class="token keyword">let</span> orig <span class="token operator">=</span> <span class="token string">&quot;The quick (\&quot;brown\&quot;) fox can't jump 32.3 feet, right? Brr, it's 29.3°F!&quot;</span><span class="token punctuation">;</span>
    
    <span class="token comment">// create the builder.</span>
    <span class="token keyword">let</span> <span class="token keyword">mut</span> builder <span class="token operator">=</span> <span class="token class-name">TokenizerBuilder</span><span class="token punctuation">::</span><span class="token function">new</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    
    <span class="token comment">// create a set of stop words.</span>
    <span class="token keyword">let</span> stop_words <span class="token operator">=</span> <span class="token class-name">Set</span><span class="token punctuation">::</span><span class="token function">from_iter</span><span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">&quot;the&quot;</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token function">iter</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">unwrap</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    
    <span class="token comment">// configurate stop words.</span>
    builder<span class="token punctuation">.</span><span class="token function">stop_words</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>stop_words<span class="token punctuation">)</span><span class="token punctuation">;</span>
    
    <span class="token comment">// build the tokenizer passing the text to tokenize.</span>
    <span class="token keyword">let</span> tokenizer <span class="token operator">=</span> builder<span class="token punctuation">.</span><span class="token function">build</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    
    <span class="token comment">// tokenize original string</span>
    <span class="token keyword">let</span> <span class="token keyword">mut</span> tokens <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span><span class="token function">tokenize</span><span class="token punctuation">(</span>orig<span class="token punctuation">)</span><span class="token punctuation">;</span>
    
    <span class="token keyword">let</span> <span class="token class-name">Token</span> <span class="token punctuation">{</span> lemma<span class="token punctuation">,</span> kind<span class="token punctuation">,</span> <span class="token punctuation">..</span> <span class="token punctuation">}</span> <span class="token operator">=</span> tokens<span class="token punctuation">.</span><span class="token function">next</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">unwrap</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token macro property">assert_eq!</span><span class="token punctuation">(</span>lemma<span class="token punctuation">,</span> <span class="token string">&quot;the&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token macro property">assert_eq!</span><span class="token punctuation">(</span>kind<span class="token punctuation">,</span> <span class="token class-name">TokenKind</span><span class="token punctuation">::</span><span class="token class-name">Word</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

    <span class="token keyword">let</span> <span class="token class-name">Token</span> <span class="token punctuation">{</span> lemma<span class="token punctuation">,</span> kind<span class="token punctuation">,</span> <span class="token punctuation">..</span> <span class="token punctuation">}</span> <span class="token operator">=</span> tokens<span class="token punctuation">.</span><span class="token function">next</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">unwrap</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token macro property">assert_eq!</span><span class="token punctuation">(</span>lemma<span class="token punctuation">,</span> <span class="token string">&quot; &quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token macro property">assert_eq!</span><span class="token punctuation">(</span>kind<span class="token punctuation">,</span> <span class="token class-name">TokenKind</span><span class="token punctuation">::</span><span class="token class-name">Separator</span><span class="token punctuation">(</span><span class="token class-name">SeparatorKind</span><span class="token punctuation">::</span><span class="token class-name">Soft</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

    <span class="token keyword">let</span> <span class="token class-name">Token</span> <span class="token punctuation">{</span> lemma<span class="token punctuation">,</span> kind<span class="token punctuation">,</span> <span class="token punctuation">..</span> <span class="token punctuation">}</span> <span class="token operator">=</span> tokens<span class="token punctuation">.</span><span class="token function">next</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">unwrap</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token macro property">assert_eq!</span><span class="token punctuation">(</span>lemma<span class="token punctuation">,</span> <span class="token string">&quot;quick&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token macro property">assert_eq!</span><span class="token punctuation">(</span>kind<span class="token punctuation">,</span> <span class="token class-name">TokenKind</span><span class="token punctuation">::</span><span class="token class-name">Word</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre></div><p>The call to the tokenize method allows the reuse of the same <code>Tokenizer</code> instance, and keep its configuration state and allocations.</p> <p>Below are examples of the integration of the new tokenizer in existing code:</p> <ul><li>Highlight in @kerollmops milli:</li></ul> <div class="language-rust extra-class"><pre class="language-rust"><code><span class="token comment">// new tokenizer</span>
<span class="token keyword">fn</span> <span class="token function-definition function">highlight_record</span><span class="token punctuation">(</span>record<span class="token punctuation">:</span> <span class="token operator">&amp;</span><span class="token keyword">mut</span> <span class="token class-name">IndexMap</span><span class="token operator">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token operator">&gt;</span><span class="token punctuation">,</span> words<span class="token punctuation">:</span> <span class="token operator">&amp;</span><span class="token class-name">HashSet</span><span class="token operator">&lt;</span><span class="token class-name">String</span><span class="token operator">&gt;</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
    <span class="token comment">// create the builder.</span>
    <span class="token keyword">let</span> <span class="token keyword">mut</span> builder <span class="token operator">=</span> <span class="token class-name">TokenizerBuilder</span><span class="token punctuation">::</span><span class="token function">new</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    
    <span class="token comment">// create a set of stop words.</span>
    <span class="token keyword">let</span> stop_words <span class="token operator">=</span> <span class="token class-name">Set</span><span class="token punctuation">::</span><span class="token function">from_iter</span><span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">&quot;the&quot;</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token function">iter</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">unwrap</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    
    <span class="token comment">// configurate stop words.</span>
    builder<span class="token punctuation">.</span><span class="token function">stop_words</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>stop_words<span class="token punctuation">)</span><span class="token punctuation">;</span>
    
    <span class="token comment">// build the tokenizer passing the text to tokenize.</span>
    <span class="token keyword">let</span> tokenizer <span class="token operator">=</span> builder<span class="token punctuation">.</span><span class="token function">build</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

    <span class="token keyword">for</span> <span class="token punctuation">(</span>_key<span class="token punctuation">,</span> value<span class="token punctuation">)</span> <span class="token keyword">in</span> record<span class="token punctuation">.</span><span class="token function">iter_mut</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
        <span class="token keyword">let</span> old_value <span class="token operator">=</span> <span class="token namespace">mem<span class="token punctuation">::</span></span><span class="token function">take</span><span class="token punctuation">(</span>value<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// reuse tokenizer at each iteration</span>
        <span class="token keyword">let</span> tokens <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span><span class="token function">reconstruct</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>old_value<span class="token punctuation">)</span><span class="token punctuation">;</span>
        
        <span class="token keyword">for</span> <span class="token punctuation">(</span>original<span class="token punctuation">,</span> token<span class="token punctuation">)</span> <span class="token keyword">in</span> tokens <span class="token punctuation">{</span>
            <span class="token keyword">if</span> token<span class="token punctuation">.</span><span class="token function">is_word</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
                <span class="token keyword">let</span> to_highlight <span class="token operator">=</span> words<span class="token punctuation">.</span><span class="token function">contains</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>token<span class="token punctuation">.</span><span class="token function">text</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                <span class="token keyword">if</span> to_highlight <span class="token punctuation">{</span> value<span class="token punctuation">.</span><span class="token function">push_str</span><span class="token punctuation">(</span><span class="token string">&quot;&lt;mark&gt;&quot;</span><span class="token punctuation">)</span> <span class="token punctuation">}</span>
                value<span class="token punctuation">.</span><span class="token function">push_str</span><span class="token punctuation">(</span>original<span class="token punctuation">)</span><span class="token punctuation">;</span>
                <span class="token keyword">if</span> to_highlight <span class="token punctuation">{</span> value<span class="token punctuation">.</span><span class="token function">push_str</span><span class="token punctuation">(</span><span class="token string">&quot;&lt;/mark&gt;&quot;</span><span class="token punctuation">)</span> <span class="token punctuation">}</span>
            <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token punctuation">{</span>
                value<span class="token punctuation">.</span><span class="token function">push_str</span><span class="token punctuation">(</span>original<span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token punctuation">}</span>
        <span class="token punctuation">}</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre></div><div class="language-rust extra-class"><pre class="language-rust"><code><span class="token comment">// original</span>
<span class="token keyword">fn</span> <span class="token function-definition function">highlight_record</span><span class="token punctuation">(</span>record<span class="token punctuation">:</span> <span class="token operator">&amp;</span><span class="token keyword">mut</span> <span class="token class-name">IndexMap</span><span class="token operator">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token operator">&gt;</span><span class="token punctuation">,</span> words<span class="token punctuation">:</span> <span class="token operator">&amp;</span><span class="token class-name">HashSet</span><span class="token operator">&lt;</span><span class="token class-name">String</span><span class="token operator">&gt;</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
    <span class="token keyword">for</span> <span class="token punctuation">(</span>_key<span class="token punctuation">,</span> value<span class="token punctuation">)</span> <span class="token keyword">in</span> record<span class="token punctuation">.</span><span class="token function">iter_mut</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
        <span class="token keyword">let</span> old_value <span class="token operator">=</span> <span class="token namespace">mem<span class="token punctuation">::</span></span><span class="token function">take</span><span class="token punctuation">(</span>value<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token keyword">for</span> <span class="token punctuation">(</span>token_type<span class="token punctuation">,</span> token<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token function">simple_tokenizer</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>old_value<span class="token punctuation">)</span> <span class="token punctuation">{</span>
            <span class="token keyword">if</span> token_type <span class="token operator">==</span> <span class="token class-name">TokenType</span><span class="token punctuation">::</span><span class="token class-name">Word</span> <span class="token punctuation">{</span>
                <span class="token keyword">let</span> lowercase_token <span class="token operator">=</span> token<span class="token punctuation">.</span><span class="token function">to_lowercase</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                <span class="token keyword">let</span> to_highlight <span class="token operator">=</span> words<span class="token punctuation">.</span><span class="token function">contains</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>lowercase_token<span class="token punctuation">)</span><span class="token punctuation">;</span>
                <span class="token keyword">if</span> to_highlight <span class="token punctuation">{</span> value<span class="token punctuation">.</span><span class="token function">push_str</span><span class="token punctuation">(</span><span class="token string">&quot;&lt;mark&gt;&quot;</span><span class="token punctuation">)</span> <span class="token punctuation">}</span>
                value<span class="token punctuation">.</span><span class="token function">push_str</span><span class="token punctuation">(</span>token<span class="token punctuation">)</span><span class="token punctuation">;</span>
                <span class="token keyword">if</span> to_highlight <span class="token punctuation">{</span> value<span class="token punctuation">.</span><span class="token function">push_str</span><span class="token punctuation">(</span><span class="token string">&quot;&lt;/mark&gt;&quot;</span><span class="token punctuation">)</span> <span class="token punctuation">}</span>
            <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token punctuation">{</span>
                value<span class="token punctuation">.</span><span class="token function">push_str</span><span class="token punctuation">(</span>token<span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token punctuation">}</span>
        <span class="token punctuation">}</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre></div><p>As we can see, the changes that need to be made are very minimal: this is because efforts have been made to make its API close to the previous one.</p> <h3 id="impact-on-documentation"><a href="#impact-on-documentation" class="header-anchor">#</a> Impact on documentation</h3> <p>This feature should not impact meilisearch users' documentation.
In future versions, we will probably provide a way to configure tokenizer and this will be discussed in a new specification.</p> <h2 id="technical-specifications"><a href="#technical-specifications" class="header-anchor">#</a> Technical Specifications</h2> <h3 id="architecture"><a href="#architecture" class="header-anchor">#</a> Architecture</h3> <p>The new version of the tokenizer will replace the current version as a <a href="https://crates.io/crates/charabia" target="_blank" rel="noopener noreferrer">standalone library named charabia<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>.</p> <h3 id="implementation-details"><a href="#implementation-details" class="header-anchor">#</a> Implementation Details</h3> <p>We want to support different tokenizers based on the language of the text that needs to be indexed. For this, we may need to change the tokenizer we are using while indexing, depending on the language and the script, detected by <code>whatlang</code>. The Tokenizer provides an interface that abstracts this need away from the consumer of the tokens.</p> <p>See <a href="https://docs.rs/charabia" target="_blank" rel="noopener noreferrer">the official documentation<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> to know more about the API of the library.</p> <p>See the repository <a href="https://github.com/meilisearch/charabia/blob/main/CONTRIBUTING.md" target="_blank" rel="noopener noreferrer">Contributing.md<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> to know more about contribution that can be made by the community.</p> <h2 id="future-possibilities"><a href="#future-possibilities" class="header-anchor">#</a> Future possibilities</h2> <ul><li>We should add a way to configure the tokenizer to enforce a specific language/script</li> <li>We should add a way to configure tokenizer whitelisting/blacklisting separators</li> <li>The tokenizer specified here is based on scripts, we should base it on languages to be able to have default stop-words for each language</li> <li>We will want in the future to allow user configuration for the tokenizer. This is taken into account in the design of the new Tokenizer.</li></ul></div> <footer class="page-edit"><!----> <!----></footer> <div class="page-nav"><p class="inner"><span class="prev">
      ←
      <a href="/specifications/text/0001-frontend-disable-prod.html" class="prev">
        Frontend disable prod
      </a></span> <span class="next"><a href="/specifications/text/0028-indexing-csv.html">
        Indexing csv
      </a>
      →
    </span></p></div> </main></div><div class="global-ui"></div></div>
    <script src="/assets/js/app.9c8da528.js" defer></script><script src="/assets/js/3.7860be15.js" defer></script><script src="/assets/js/14.9305fa09.js" defer></script>
  </body>
</html>
